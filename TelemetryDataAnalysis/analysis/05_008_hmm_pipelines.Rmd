---
title: "Hidden Markov Model-based learning pipelines"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "#>", dpi = 500)

suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(depmixS4))

source(here::here("start.R"))
theme_set(theme_minimal())
set.seed(0)
```

Below, I try out a few HMM-based modeling and prediciton pipelines.

## Data

```{r, warning=FALSE}
zscale <- function(x, na.rm = TRUE) {
  (x - mean(x, na.rm = na.rm)) / sd(x, na.rm = na.rm)
}


apply_scale_trans <- function(df, x = value, y = scaled_value) {
  df %.% {
    group_by(axis, motion)
    mutate({{ y }} := zscale({{ x }}))
    ungroup()
  }
}


running_fxn <- function(x, fxn, n = 5) {
  y <- x
  for (i in seq(1, length(x))) {
    x_i <- c()
    for (j in seq(-n, n)) {
      idx <- i + j
      if (idx < 1 | idx > length(x)) { next }
      x_i <- c(x_i, x[[idx]])
    }
    y[[i]] <- fxn(x_i)
  }
  return(y)
}


apply_smoothing_trans <- function(df, 
                                  x = value, 
                                  y = smooth_value, 
                                  rolling_n = 10) {
  df %.% {
    group_by(axis, motion)
    mutate(
      {{ y }} := running_fxn(abs({{ x }}), fxn = max, n = rolling_n),
      {{ y }} := ksmooth(date, {{ y }}, kernel = "box")$y
    )
  }
}



transform_pushup_data <- function(df) {
  df %>%
    apply_scale_trans() %>%
    apply_smoothing_trans(x = scaled_value)
}


pushup_data <- tibble(filename = get_data_file_names(data_dir)) %.% {
  filter(str_detect(filename, "Push"))
  mutate(
    workout_idx = row_number(),
    all_data = map(filename, read_watch_data),
    file_info = map(all_data, ~ .x$meta_data),
    data = map(all_data, ~ .x$telemetry_data),
    data = map(data, transform_pushup_data),
    data = map(data, ~ rename(.x, time_step = date)),
    data = map(data, ~ select(.x,
      time_step, idx, motion, axis, value, scaled_value, smooth_value
    ))
  )
  select(-all_data, -filename)
  unnest(file_info)
  select(workout_idx, exercise, reps, date, data)
}

pushup_data
```

## Pipeline #1. Heuristic chop & simple HMM

### Overview

**Pipeline**

1. Chop the raw data within an IQR of the time steps to get just the clena pushup data.
2. Use an HMM to identify the 2 states of the push-up.
3. Use the HMM to cut the chopped data into the two states of training a classifier.
4. Train an classifier on this training data.
5. Apply the classifier to the original data to test accuracy.

**Experimental features**

1. The type of classifier to use.
2. Would it be possible to train the classifer with *3* classes, one being "unknown" and having this be the very beginning and ending data?

### Pipeline

#### 1. Chop the data

Select only the time steps in the 30 and 70 percentiles.

```{r}
chopped_pushup_data <- pushup_data %.% {
  unnest(data)
  group_by(workout_idx)
  filter(time_step > quantile(time_step, 0.3) & time_step < quantile(time_step, 0.7))
  ungroup()
}

# Number of data points per workout.
chopped_pushup_data %>%
  group_by(workout_idx) %>%
  summarise(n_datapoints = n_distinct(idx)) %>%
  ungroup()

chopped_pushup_data %>%
  ggplot(aes(x = time_step, y = smooth_value)) +
  facet_wrap(~ workout_idx, scales = "free", ncol = 2) +
  geom_line(aes(color = axis))
```

#### 2. Train HMM

```{r}
nest_pushup_exercises <- function(df) {
  df %>%
    group_by(workout_idx, exercise, reps, date) %>%
    nest() %>%
    ungroup()
}

pivot_telemetry_data <- function(telemetry_data, x = value) {
  telemetry_data %>%
    pivot_wider(
      c(time_step, idx),
      names_from = axis,
      values_from = {{ x }}
    )
}
```


```{r}
construct_pushup_hmm <- function(d, nstates = 2) {
  depmix(
    list(
      x ~ 1,
      y ~ 1,
      z ~ 1,
      pitch ~ 1,
      roll ~ 1,
      yaw ~ 1
    ),
    nstates = nstates,
    family = list(
      gaussian(), gaussian(), gaussian(),
      gaussian(), gaussian(), gaussian()
    ),
    data = d
  )
}



chopped_pushup_hmms <- chopped_pushup_data %.% {
  nest_pushup_exercises()
  mutate(
    wide_data = map(data, pivot_telemetry_data, x = smooth_value),
    model = map(wide_data, construct_pushup_hmm),
    fit = map(model, fit)
  )
}
```

```{r}
plot_telmetry_data <- function(df, x = value) {
  df %>%
    mutate(motion = str_to_title(motion)) %>%
    ggplot(aes(idx, {{ x }})) +
    facet_wrap(~ motion, ncol = 1, scales = "free_y") +
    geom_line(aes(color = axis), alpha = 0.7) +
    scale_color_brewer(type = "qual", palette = "Dark2") +
    theme(
      strip.text = element_text(hjust = 0.5, size = 11)
    )
}

plot_hmm_results <- function(hmm_fit) {
  posterior(hmm_fit) %>%
    as_tibble() %>%
    mutate(idx = row_number()) %>%
    pivot_longer(-c(idx, state)) %>%
    ggplot(aes(x = idx, y = value, color = name)) +
    facet_grid(name ~ .) +
    geom_line(size = 1, alpha = 0.8) +
    scale_color_brewer(type = "qual", palette = "Set1") +
    scale_y_continuous(breaks = c(0, 0.5, 1)) +
    theme(
      plot.title = element_text(hjust = 0.5, size = 11),
    ) +
    labs(
      x = "data point",
      y = "probability of state",
      color = "state",
      title = "Hidden Markov Model states"
    )
}


plot_hmm_fit <- function(data, hmm_fit, data_x) {
  data_plot <- plot_telmetry_data(data, x = {{ data_x }}) +
    theme(axis.title.x = element_blank())
  hmm_plot <- plot_hmm_results(hmm_fit)
  patch <- data_plot / hmm_plot + plot_layout(heights = c(3, 1))
  plot(patch)
  return(NULL)
}

chopped_pushup_hmms %>%
  mutate(a = walk2(data, fit, plot_hmm_fit, data_x = smooth_value))
```

#### 3. Prepare training data with the HMM

This step is currently being worked on

```{r}
hmm <- chopped_pushup_hmms$fit[[1]]
d <- chopped_pushup_hmms$wide_data[[1]]
summary(hmm)
```

```{r}
training_data_1 <- posterior(hmm) %>%
  bind_cols(d) %>%
  mutate(state = case_when(
    S1 > 0.95 ~ "state1",
    S2 > 0.95 ~ "state2",
    TRUE ~ "unknown"
  ))

training_data_2 <- pushup_data %.% {
  slice(1)
  unnest(data)
  filter(time_step < quantile(time_step, 0.1) | time_step > quantile(time_step, 0.9))
  pivot_telemetry_data(x = smooth_value)
  add_column(state = "unknown")
}

training_data <- bind_rows(training_data_1, training_data_2)
training_data
```

```{r}
table(training_data$state)
```

A t-SNE plot of the data made to train the classifiers.

```{r}
training_data_tsne <- training_data %.% {
  ~~ original_data <- .
  select(-S1, -S2, -time_step, -state)
  as.data.frame()
  column_to_rownames("idx")
  unique()
  ~~ min_data <- .
  Rtsne::Rtsne()
  .$Y
  as.data.frame()
  mutate(idx = as.numeric(rownames(min_data)))
  left_join(original_data, by = "idx")
}

training_data_tsne %>%
  ggplot(aes(V1, V2, color = state)) +
  geom_jitter(size = 1.4, alpha = 0.6, height = 0.5, width = 0.5) +
  scale_color_manual(values = c("orange", "purple", "black")) +
  labs(
    x = "t-SNE 1",
    y = "t-SNE 2",
    title = "t-SNE of push-up telemetry data"
  )
```


```{r}

# Append a prefix to each column name of a data frame.
prefix_colnames <- function(d, prefix) {
  colnames(d) <- paste0(prefix, colnames(d))
  return(d)
}

# Collect classification ROC results.
pushup_classification_roc <- function(fit, train_data, test_data) {
  f <- function(fit, data) {
    pred_data <- predict(fit, data, type = "prob") %>%
      bind_cols(data)
    roc_curve <- roc_curve(
      pred_data,
      truth = factor(state), 
      .pred_state1, .pred_state2, .pred_unknown
    )
    roc_auc_est <- roc_auc(
      pred_data, 
      truth = factor(state), 
      .pred_state1, .pred_state2, .pred_unknown
    )
    return(tibble(
      pred_prob = list(pred_data),
      roc_curve = list(roc_curve),
      roc_auc = roc_auc_est$.estimate[[1]]
    ))
  }
  
  train_pred <- f(fit, train_data) %>% prefix_colnames("train_")
  test_pred <- f(fit, test_data) %>% prefix_colnames("test_")
  bind_cols(train_pred, test_pred)
}

# Collect classification metrics.
pushup_classification_metrics <- function(fit, train_data, test_data) {
  
  metric_f <- function(pred_data, fxn) {
    fxn(pred_data, state, .pred_class)$.estimate[[1]]
  }
  
  f <- function(fit, data) {
    pred_data <- predict(fit, data, type = "class") %>%
      bind_cols(data) %>%
      mutate(state = factor(state))
    tibble(
      pred_class = list(pred_data),
      sensitivity = metric_f(pred_data, sensitivity),
      specificity = metric_f(pred_data, specificity),
      precision = metric_f(pred_data, precision),
      mcc = metric_f(pred_data, mcc),
      fmeasure = metric_f(pred_data, f_meas),
      accuracy = metric_f(pred_data, accuracy),
      kap = metric_f(pred_data, kap),
      ppv = metric_f(pred_data, ppv),
      npv = metric_f(pred_data, npv)
    )
  }
  
  train_pred <- f(fit, train_data) %>% prefix_colnames("train_")
  test_pred <- f(fit, test_data) %>% prefix_colnames("test_")
  bind_cols(train_pred, test_pred)
}


knn_assessment_workflow <- function(fit, train_data, test_data) {
  roc_results <- pushup_classification_roc(fit, train_data, test_data)
  class_results <- pushup_classification_metrics(fit, train_data, test_data)
  return(bind_cols(roc_results, class_results))
}

run_knn_workflow <- function(data, prop = 0.75) {
  
  data_split <- initial_split(data, prop = prop, strata = "state")

  pushup_recipe <- recipe(
    state ~ x + y + z + pitch + roll + yaw, 
    data = training_data
  )
  
  # Model specification.
  knn_spec <- nearest_neighbor(mode = "classification") %>%
    set_engine("kknn")
  
  # TidyModels workflow.
  pushup_workflow <- workflow() %>%
    add_model(knn_spec) %>%
    add_recipe(pushup_recipe)
  
  # Data.
  train_data <- training(data_split)
  test_data <- testing(data_split)
  
  # Fit the model.
  pushup_knn_fit <- parsnip::fit(pushup_workflow, data = train_data)

  # Get model assessment values.
  model_assessment <- knn_assessment_workflow(
    pushup_knn_fit, 
    train_data, 
    test_data
  )
  return(model_assessment)
}


run_knn_workflow(training_data)
```

```{r}

```

**To-Do**:

- continue with the practice sample started above:
  - look into using TidyModels for the following analysis
  - split the data into training and testing data
  - fit a few different classifiers with this training data and see how well they do
    - decision forest, decision tree, kNN, SVM, naive Bayes